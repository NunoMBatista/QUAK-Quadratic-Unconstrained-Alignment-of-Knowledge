{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d3f91fc",
   "metadata": {},
   "source": [
    "# Hypothetical Hybrid GNN-QUBO Alignment Pipeline\n",
    "\n",
    "Keep in mind that this Jupyter notebook's purpose is not to show an advantage of the QUBO method over the NN method. \n",
    "\n",
    "This is just a proposed pipeline for QUBO re-ranking. \n",
    "\n",
    "It implements all of the steps, from data fetching to the QUBO solver.\n",
    "\n",
    "We start by building two regular knowledge graphs (unpruned) and then prune them to simulate how a smaller knowledge graph would look like (in theory, that smaller knowledge graph would contain the ambiguous entities which didn't get a high alignment confidence score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6368166",
   "metadata": {},
   "source": [
    "## Section 1: Load Project Dependencies\n",
    "- Set up the Python path for the project and import every module that the pipeline relies on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407be95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nuno/python_envs/KGA/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from types import SimpleNamespace\n",
    "import webbrowser\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, IFrame, display\n",
    "\n",
    "repo_root = Path().resolve().parent\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from src.config import *\n",
    "from src.evaluation.solvers import (\n",
    "    solve_alignment_with_annealer,\n",
    "    solve_alignment_with_nearest_neighbor,\n",
    " )\n",
    "from src.kg_construction.fetch_data import fetch_wiki_data, fetch_arxiv_data\n",
    "from src.kg_construction.build_kg import build_unpruned_kgs, prune_kgs\n",
    "from src.embedding.generate_embeddings import (\n",
    "    generate_relation_embeddings,\n",
    "    generate_entity_embeddings,\n",
    " )\n",
    "from src.utils.graph_visualizer import visualize_ttl\n",
    "\n",
    "# [FIX THIS LATER] maintain backward-compatible variable name for existing cells\n",
    "ALIGNED_ENTITIES_CSV = ALIGNED_ENTITIES_ANNEALER_CSV\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# create directories if they don't exist\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "KG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ENTITIES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WIKI_ENTITIES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ARXIV_ENTITIES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _open_in_browser(path, title):\n",
    "    \"\"\"Open a local HTML file in the default browser.\"\"\"\n",
    "    path = Path(path)\n",
    "    webbrowser.open(f\"file://{path.resolve()}\")\n",
    "    display(HTML(f\"<p><i>Opening '{title}' in the browser...</i></p>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc7687",
   "metadata": {},
   "source": [
    "## Section 2: Data Preparation\n",
    "- Fetch the Wikipedia and arXiv raw data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58de790a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching source corpora...\n",
      "-> all requested Wikipedia articles already cached; reusing local files\n",
      "    -> returning 10 Wikipedia summaries.\n",
      "-> all requested arXiv abstracts already cached; reusing local files\n",
      "    -> returning 10 arXiv abstracts.\n",
      "Wikipedia titles: ['Quantum algorithm', 'Post-quantum cryptography', 'Quantum optimization algorithms', 'Quantum computing', \"Shor's algorithm\", \"Grover's algorithm\", 'Noisy intermediate-scale quantum computing', 'Quantum machine learning', 'Quantum counting algorithm', 'Quantum phase estimation algorithm']\n",
      "arXiv IDs: ['2310.03011v2', '2406.13258v3', '2312.13636v3', '0708.0261v1', 'quant-ph/9508027v2', '2108.10854v2', '1801.00862v3', '1611.09347v2', 'quant-ph/9805082v1', 'quant-ph/9511026v1']\n"
     ]
    }
   ],
   "source": [
    "wiki_titles = []\n",
    "arxiv_ids = []\n",
    "\n",
    "\n",
    "print(\"Fetching source corpora...\")\n",
    "wiki_summaries, wiki_titles = fetch_wiki_data()\n",
    "arxiv_abstracts, arxiv_ids = fetch_arxiv_data()\n",
    "print(f\"Wikipedia titles: {wiki_titles}\")\n",
    "print(f\"arXiv IDs: {arxiv_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df661f0",
   "metadata": {},
   "source": [
    "# Section 3: Build the KGs.\n",
    "\n",
    "- Run the NLP pipeline to perform Named Entity Recognition (NER) and Relationship Extraction (RE) on the raw data.\n",
    "\n",
    "- Use the entities and the relations between them to build two large unpruned graphs.\n",
    "\n",
    "- Take the unpruned graphs and reduce them to just a couple entities. In practice, those would be tha \"ambiguous\" entities whose alignment confidence score is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a69849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building and pruning knowledge graphs...\n",
      "\n",
      "--- STEP 1: RUN THE NLP PIPELINE ---\n",
      "-> NLTK 'punkt' tokenizer model found.\n",
      "-> NLTK 'punkt_tab' tokenizer model found.\n",
      "-> SciBERT NER model loaded.\n",
      "-> Saved 387 wiki entities to /home/nuno/Documents/QUBO-KGA/output/entities/wiki_entities/entities.txt\n",
      "-> Saved 282 arXiv entities to /home/nuno/Documents/QUBO-KGA/output/entities/arxiv_entities/entities.txt\n",
      "\n",
      "--- STEP 2: BUILD THE UNPRUNED KGs ---\n",
      "-> Wiki triples extracted: 55\n",
      "-> arXiv triples extracted: 13\n",
      "-> Unique wiki relations: 18\n",
      "-> Unique arXiv relations: 10\n",
      "\n",
      "-> Saving 55 wiki triples to /home/nuno/Documents/QUBO-KGA/output/KGs/kg_wiki_unpruned.ttl\n",
      "-> Saving 13 arXiv triples to /home/nuno/Documents/QUBO-KGA/output/KGs/kg_arxiv_unpruned.ttl\n",
      "loading graph from: /home/nuno/Documents/QUBO-KGA/output/KGs/kg_wiki_unpruned.ttl\n",
      "\n",
      "saved graph visualization to: /home/nuno/Documents/QUBO-KGA/output/KGs/unpruned_wiki_kg.html\n",
      "loading graph from: /home/nuno/Documents/QUBO-KGA/output/KGs/kg_arxiv_unpruned.ttl\n",
      "\n",
      "saved graph visualization to: /home/nuno/Documents/QUBO-KGA/output/KGs/unpruned_arxiv_kg.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><i>Opening 'Unpruned Wiki Knowledge Graph' in the browser...</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><i>Opening 'Unpruned arXiv Knowledge Graph' in the browser...</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nBuilding and pruning knowledge graphs...\")\n",
    "build_unpruned_kgs(\n",
    "    wiki_data=wiki_summaries, \n",
    "    arxiv_data=arxiv_abstracts\n",
    ")\n",
    "\n",
    "visualize_ttl(KG_WIKI_UNPRUNED_PATH, KG_DIR / \"unpruned_wiki_kg.html\")\n",
    "visualize_ttl(KG_ARXIV_UNPRUNED_PATH, KG_DIR / \"unpruned_arxiv_kg.html\")\n",
    "\n",
    "\n",
    "_open_in_browser(KG_DIR / \"unpruned_wiki_kg.html\", \"Unpruned Wiki Knowledge Graph\")\n",
    "_open_in_browser(KG_DIR / \"unpruned_arxiv_kg.html\", \"Unpruned arXiv Knowledge Graph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b5f5b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STEP 4: PRUNING KGs ---\n",
      "\n",
      "-> pruning Wiki KG...\n",
      "    -> loaded 55 raw triples, pruning with 9 entities.\n",
      "    -> Found and added 4 matching entities.\n",
      "    -> Saving 5 clean triples to /home/nuno/Documents/QUBO-KGA/output/KGs/kg_wiki_final.ttl\n",
      "\n",
      "-> pruning arXiv KG...\n",
      "    -> loaded 13 raw triples, pruning with 9 entities.\n",
      "    -> Found and added 1 matching entities.\n",
      "    -> Saving 1 clean triples to /home/nuno/Documents/QUBO-KGA/output/KGs/kg_arxiv_final.ttl\n",
      "loading graph from: /home/nuno/Documents/QUBO-KGA/output/KGs/kg_wiki_final.ttl\n",
      "\n",
      "saved graph visualization to: /home/nuno/Documents/QUBO-KGA/output/KGs/pruned_wiki_kg.html\n",
      "loading graph from: /home/nuno/Documents/QUBO-KGA/output/KGs/kg_arxiv_final.ttl\n",
      "\n",
      "saved graph visualization to: /home/nuno/Documents/QUBO-KGA/output/KGs/pruned_arxiv_kg.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><i>Opening 'Pruned Wiki Knowledge Graph' in the browser...</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><i>Opening 'Pruned arXiv Knowledge Graph' in the browser...</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prune_kgs()\n",
    "\n",
    "wiki_html = KG_DIR / \"pruned_wiki_kg.html\"\n",
    "arxiv_html = KG_DIR / \"pruned_arxiv_kg.html\"\n",
    "visualize_ttl(KG_WIKI_FINAL_PATH, wiki_html)\n",
    "visualize_ttl(KG_ARXIV_FINAL_PATH, arxiv_html)\n",
    "\n",
    "# Open HTML files in browser\n",
    "_open_in_browser(wiki_html, \"Pruned Wiki Knowledge Graph\")\n",
    "_open_in_browser(arxiv_html, \"Pruned arXiv Knowledge Graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886dae0",
   "metadata": {},
   "source": [
    "## Section 4: Generate Embeddings\n",
    "Generate the following embeddings:\n",
    "- Entity embeddings (using a GAE that fine-tunes the SciBERT embeddings)\n",
    "- Relation embeddings (using the SciBERT embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50efc103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating relation embeddings...\n",
      "\n",
      "--- Part 1: Generating Relation Embeddings (for H_structure) ---\n",
      "Loading SciBERT model: allenai/scibert_scivocab_cased...\n",
      "Discovered 26 relation labels.\n",
      "  - amplify\n",
      "  - break\n",
      "  - demand\n",
      "  - design\n",
      "  - employ\n",
      "  - enable\n",
      "  - encounter\n",
      "  - enter\n",
      "  - examine\n",
      "  - investigate\n",
      "  - is a\n",
      "  - limit\n",
      "  - manipulate\n",
      "  - outperform\n",
      "  - perform\n",
      "  - pose\n",
      "  - produce\n",
      "  - propose\n",
      "  - provide\n",
      "  - release\n",
      "  - remain\n",
      "  - require\n",
      "  - run\n",
      "  - solve\n",
      "  - speed\n",
      "  - use\n",
      "Successfully saved relation embeddings to /home/nuno/Documents/QUBO-KGA/output/embeddings/relation_embeddings.npz\n",
      "\n",
      "Generating entity embeddings...\n",
      "\n",
      "--- Part 2: Generating Entity Embeddings (for H_node) ---\n",
      "\n",
      "Processing Wiki KG:\n",
      "  Loading graph from /home/nuno/Documents/QUBO-KGA/output/KGs/kg_wiki_unpruned.ttl...\n",
      "  Generating SciBERT features for nodes...\n",
      "  Graph loaded: 78 nodes, 186 edges.\n",
      "\n",
      "Processing ArXiv KG:\n",
      "  Loading graph from /home/nuno/Documents/QUBO-KGA/output/KGs/kg_arxiv_unpruned.ttl...\n",
      "  Generating SciBERT features for nodes...\n",
      "  Graph loaded: 24 nodes, 50 edges.\n",
      "  Training joint GAEA for 500 epochs...\n",
      "    Epoch 1/500, Loss: 1.4587, Wiki recon: 0.7247, ArXiv recon: 0.7252, MMD: 0.0177, Stats: 0.0000, Wiki pos/neg: 0.628/0.626, ArXiv pos/neg: 0.627/0.626\n",
      "    Epoch 20/500, Loss: 1.4466, Wiki recon: 0.7232, ArXiv recon: 0.7229, MMD: 0.0009, Stats: 0.0000, Wiki pos/neg: 0.624/0.623, ArXiv pos/neg: 0.624/0.623\n",
      "    Epoch 40/500, Loss: 1.4362, Wiki recon: 0.7214, ArXiv recon: 0.7192, MMD: -0.0088, Stats: 0.0001, Wiki pos/neg: 0.627/0.623, ArXiv pos/neg: 0.628/0.622\n",
      "    Epoch 60/500, Loss: 1.4061, Wiki recon: 0.7121, ArXiv recon: 0.7012, MMD: -0.0146, Stats: 0.0001, Wiki pos/neg: 0.645/0.626, ArXiv pos/neg: 0.648/0.620\n",
      "    Epoch 80/500, Loss: 1.3473, Wiki recon: 0.6907, ArXiv recon: 0.6629, MMD: -0.0130, Stats: 0.0017, Wiki pos/neg: 0.682/0.626, ArXiv pos/neg: 0.691/0.610\n",
      "    Epoch 100/500, Loss: 1.3623, Wiki recon: 0.6676, ArXiv recon: 0.7051, MMD: -0.0210, Stats: 0.0009, Wiki pos/neg: 0.699/0.614, ArXiv pos/neg: 0.706/0.646\n",
      "    Epoch 120/500, Loss: 1.2936, Wiki recon: 0.6515, ArXiv recon: 0.6507, MMD: -0.0175, Stats: 0.0017, Wiki pos/neg: 0.706/0.604, ArXiv pos/neg: 0.722/0.611\n",
      "    Epoch 140/500, Loss: 1.2673, Wiki recon: 0.6620, ArXiv recon: 0.6137, MMD: -0.0172, Stats: 0.0018, Wiki pos/neg: 0.711/0.614, ArXiv pos/neg: 0.728/0.586\n",
      "    Epoch 160/500, Loss: 1.2598, Wiki recon: 0.6349, ArXiv recon: 0.6315, MMD: -0.0139, Stats: 0.0033, Wiki pos/neg: 0.722/0.599, ArXiv pos/neg: 0.731/0.598\n",
      "    Epoch 180/500, Loss: 1.2760, Wiki recon: 0.6687, ArXiv recon: 0.6148, MMD: -0.0155, Stats: 0.0026, Wiki pos/neg: 0.721/0.623, ArXiv pos/neg: 0.731/0.586\n",
      "    Epoch 200/500, Loss: 1.2235, Wiki recon: 0.6502, ArXiv recon: 0.5796, MMD: -0.0135, Stats: 0.0040, Wiki pos/neg: 0.722/0.609, ArXiv pos/neg: 0.731/0.558\n",
      "    Epoch 220/500, Loss: 1.2656, Wiki recon: 0.6378, ArXiv recon: 0.6352, MMD: -0.0159, Stats: 0.0058, Wiki pos/neg: 0.728/0.602, ArXiv pos/neg: 0.731/0.599\n",
      "    Epoch 240/500, Loss: 1.1699, Wiki recon: 0.6159, ArXiv recon: 0.5635, MMD: -0.0195, Stats: 0.0023, Wiki pos/neg: 0.729/0.586, ArXiv pos/neg: 0.731/0.545\n",
      "    Epoch 260/500, Loss: 1.2034, Wiki recon: 0.6116, ArXiv recon: 0.6013, MMD: -0.0196, Stats: 0.0029, Wiki pos/neg: 0.728/0.582, ArXiv pos/neg: 0.731/0.574\n",
      "    Epoch 280/500, Loss: 1.1886, Wiki recon: 0.6461, ArXiv recon: 0.5520, MMD: -0.0194, Stats: 0.0024, Wiki pos/neg: 0.728/0.606, ArXiv pos/neg: 0.731/0.537\n",
      "    Epoch 300/500, Loss: 1.1945, Wiki recon: 0.6170, ArXiv recon: 0.5871, MMD: -0.0197, Stats: 0.0031, Wiki pos/neg: 0.730/0.585, ArXiv pos/neg: 0.731/0.563\n",
      "    Epoch 320/500, Loss: 1.1834, Wiki recon: 0.6300, ArXiv recon: 0.5630, MMD: -0.0197, Stats: 0.0022, Wiki pos/neg: 0.730/0.595, ArXiv pos/neg: 0.731/0.545\n",
      "    Epoch 340/500, Loss: 1.1616, Wiki recon: 0.6076, ArXiv recon: 0.5640, MMD: -0.0203, Stats: 0.0018, Wiki pos/neg: 0.730/0.578, ArXiv pos/neg: 0.731/0.546\n",
      "    Epoch 360/500, Loss: 1.1934, Wiki recon: 0.5924, ArXiv recon: 0.6106, MMD: -0.0198, Stats: 0.0030, Wiki pos/neg: 0.729/0.566, ArXiv pos/neg: 0.731/0.580\n",
      "    Epoch 380/500, Loss: 1.2279, Wiki recon: 0.6264, ArXiv recon: 0.6109, MMD: -0.0192, Stats: 0.0027, Wiki pos/neg: 0.729/0.591, ArXiv pos/neg: 0.731/0.580\n",
      "    Epoch 400/500, Loss: 1.2479, Wiki recon: 0.6240, ArXiv recon: 0.6345, MMD: -0.0215, Stats: 0.0012, Wiki pos/neg: 0.731/0.590, ArXiv pos/neg: 0.731/0.598\n",
      "    Epoch 420/500, Loss: 1.2289, Wiki recon: 0.6161, ArXiv recon: 0.6226, MMD: -0.0204, Stats: 0.0034, Wiki pos/neg: 0.730/0.585, ArXiv pos/neg: 0.731/0.589\n",
      "    Epoch 440/500, Loss: 1.1742, Wiki recon: 0.6213, ArXiv recon: 0.5632, MMD: -0.0209, Stats: 0.0018, Wiki pos/neg: 0.731/0.589, ArXiv pos/neg: 0.731/0.545\n",
      "    Epoch 460/500, Loss: 1.2234, Wiki recon: 0.6111, ArXiv recon: 0.6225, MMD: -0.0207, Stats: 0.0015, Wiki pos/neg: 0.729/0.580, ArXiv pos/neg: 0.731/0.589\n",
      "    Epoch 480/500, Loss: 1.1982, Wiki recon: 0.6218, ArXiv recon: 0.5867, MMD: -0.0209, Stats: 0.0013, Wiki pos/neg: 0.731/0.588, ArXiv pos/neg: 0.731/0.562\n",
      "    Epoch 500/500, Loss: 1.1900, Wiki recon: 0.6012, ArXiv recon: 0.5987, MMD: -0.0204, Stats: 0.0032, Wiki pos/neg: 0.730/0.573, ArXiv pos/neg: 0.731/0.571\n",
      "Saved Wiki entity embeddings to /home/nuno/Documents/QUBO-KGA/output/embeddings/entity_embeddings_wiki.pt\n",
      "Saved ArXiv entity embeddings to /home/nuno/Documents/QUBO-KGA/output/embeddings/entity_embeddings_arxiv.pt\n"
     ]
    }
   ],
   "source": [
    "RUN_EMBEDDINGS = True\n",
    "\n",
    "if RUN_EMBEDDINGS:\n",
    "    print(\"Generating relation embeddings...\")\n",
    "    generate_relation_embeddings()\n",
    "    print(\"\\nGenerating entity embeddings...\")\n",
    "    generate_entity_embeddings()\n",
    "else:\n",
    "    print(\"Skipping embedding generation; using cached tensors.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61f0a8",
   "metadata": {},
   "source": [
    "## Section 5: Formulate the problem as a QUBO and solve it\n",
    "Perform the QUBO formulation:\n",
    "$$\n",
    "H_{total} = \\underbrace{\\sum_{i,a}{-S(i, a) \\cdot x_{i,a}}}_{H_{\\text{node}}} + \\underbrace{\\sum_{i,j,a,b}{-w_{ij,ab} \\cdot x_{i,a} \\cdot x_{j,b}}}_{H_{\\text{structure}}} + \\underbrace{\\sum_{i} P_{1} \\sum_{a=1}^M \\sum_{b=a+1}^M x_{i,a} x_{i,b}}_{\\text{Constraint}\\ 1} + \\underbrace{\\sum_{a} P_{2} \\sum_{i=1}^N \\sum_{j=i+1}^N x_{i,a} x_{j,a}}_{\\text{Constraint}\\ 2}\n",
    "$$\n",
    "\n",
    "- Where:\n",
    "  - $x_{i,a}$: A binary variable (1 or 0) that is 1 if we align entity $i$ from KG1 with entity $a$ from KG2.\n",
    "  - $S(i,a)$: The similarity score between entity $i$ and $a$, derived from the GAE embeddings.\n",
    "  - $w_{ij,ab}$: The structural similarity weight, derived from the SciBERT relation embeddings.\n",
    "  - $P_1, P_2$: Large positive penalty constants to enforce the constraints.\n",
    "  - Constraint 1: Enforces that each entity $i$ in KG1 maps to at most one entity in KG2. If $i$ matches zero entities, the penalty is 0. If it matches one, the penalty is 0. If it matches two or more, the penalty is high.\n",
    "  - Constraint 2: Enforces that each entity $a$ in KG2 is mapped to by at most one entity from KG1. This allows entities to remain unaligned, making the formulation more robust to realistic KGs that do not have perfect 1-to-1 overlap.\n",
    "\n",
    "And solve it using quantum annealing (more details in the README.md file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aab8905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving the alignment QUBO...\n",
      "[QUBO] candidate variables: 4, structural pairs: 0\n",
      "[QUBO] running simulated annealer with num_reads=100, beta_range=None, seed=None\n",
      "[QUBO] best sample energy=-0.9977 produced 1 alignments\n",
      "loading graph from: /home/nuno/Documents/QUBO-KGA/output/KGs/kg_aligned.ttl\n",
      "\n",
      "saved graph visualization to: /home/nuno/Documents/QUBO-KGA/output/KGs/aligned_kg.html\n",
      "[QUBO] alignment report saved to /home/nuno/Documents/QUBO-KGA/output/alignments/alignment_annealer.csv with 1 matches and 3 unaligned entries\n"
     ]
    }
   ],
   "source": [
    "SOLVE_QUBO = True\n",
    "\n",
    "result = None\n",
    "if SOLVE_QUBO:\n",
    "    print(\"\\nSolving the alignment QUBO...\")\n",
    "    result = solve_alignment_with_annealer(\n",
    "        similarity_threshold=0.0,\n",
    "        max_structural_pairs=2000,\n",
    "        visualize=True\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping QUBO solve; falling back to existing artefacts.\")\n",
    "\n",
    "if result is None:\n",
    "    result = SimpleNamespace(\n",
    "        alignments=[],\n",
    "        energy=float(\"nan\"),\n",
    "        sampleset=None,\n",
    "        aligned_graph_path=KG_ALIGNED_PATH,\n",
    "        aligned_graph_html=(KG_DIR / \"kg_aligned.html\"),\n",
    "        alignment_report_path=ALIGNED_ENTITIES_ANNEALER_CSV,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e3d33",
   "metadata": {},
   "source": [
    "## Section 6: Display HTML Visualizations\n",
    "Render the pruned graphs, aligned knowledge graph, and alignment report directly within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7824dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading graph from: /home/nuno/Documents/QUBO-KGA/output/KGs/kg_aligned.ttl\n",
      "\n",
      "saved graph visualization to: /home/nuno/Documents/QUBO-KGA/output/KGs/kg_aligned.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><i>Opening 'Aligned Knowledge Graph' in the browser...</i></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wiki_entity</th>\n",
       "      <th>arxiv_entity</th>\n",
       "      <th>not_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quantum computer</td>\n",
       "      <td>Quantum computers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wiki: Quantum algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wiki: Quantum devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wiki: Qubit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wiki_entity       arxiv_entity              not_aligned\n",
       "0  Quantum computer  Quantum computers                      NaN\n",
       "1               NaN                NaN  wiki: Quantum algorithm\n",
       "2               NaN                NaN    wiki: Quantum devices\n",
       "3               NaN                NaN              wiki: Qubit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming KG_DIR, result, and ALIGNED_ENTITIES_ANNEALER_CSV are defined\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "aligned_html = KG_DIR / \"kg_aligned.html\"\n",
    "# create the visualizations\n",
    "\n",
    "visualize_ttl(KG_ALIGNED_PATH, aligned_html)\n",
    "\n",
    "\n",
    "\n",
    "# aligned_html = getattr(result, \"aligned_graph_html\", None)\n",
    "# if aligned_html is None:\n",
    "#     aligned_html = KG_DIR / \"aligned_kg.html\"\n",
    "\n",
    "\n",
    "\n",
    "_open_in_browser(aligned_html, \"Aligned Knowledge Graph\")\n",
    "# # Display only the DataFrame in the notebook\n",
    "#display(HTML(\"<h3>Annealer Aligned Entities Report</h3>\"))\n",
    "display(pd.read_csv(ALIGNED_ENTITIES_ANNEALER_CSV))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KGA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
