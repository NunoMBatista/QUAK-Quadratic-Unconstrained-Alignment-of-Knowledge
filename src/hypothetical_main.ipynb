{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d3f91fc",
   "metadata": {},
   "source": [
    "# Hypothetical Hybrid GNN-QUBO Alignment Pipeline\n",
    "\n",
    "Keep in mind that this Jupyter notebook's purpose is not to show an advantage of the QUBO method over the NN method. \n",
    "\n",
    "This is just a proposed pipeline for QUBO re-ranking. \n",
    "\n",
    "It implements all of the steps, from data fetching to the QUBO solver.\n",
    "\n",
    "We start by building two regular knowledge graphs (unpruned) and then prune them to simulate how a smaller knowledge graph would look like (in theory, that smaller knowledge graph would contain the ambiguous entities which didn't get a high alignment confidence score)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6368166",
   "metadata": {},
   "source": [
    "## Section 1: Load Project Dependencies\n",
    "- Set up the Python path for the project and import every module that the pipeline relies on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407be95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "from types import SimpleNamespace\n",
    "import webbrowser\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, IFrame, display\n",
    "\n",
    "repo_root = Path().resolve().parent\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from src.config import *\n",
    "from src.evaluation.solvers import (\n",
    "    solve_alignment_with_annealer,\n",
    "    solve_alignment_with_nearest_neighbor,\n",
    " )\n",
    "from src.kg_construction.fetch_data import fetch_wiki_data, fetch_arxiv_data\n",
    "from src.kg_construction.build_kg import build_unpruned_kgs, prune_kgs\n",
    "from src.embedding.generate_embeddings import (\n",
    "    generate_relation_embeddings,\n",
    "    generate_entity_embeddings,\n",
    " )\n",
    "from src.utils.graph_visualizer import visualize_ttl\n",
    "\n",
    "# [FIX THIS LATER] maintain backward-compatible variable name for existing cells\n",
    "ALIGNED_ENTITIES_CSV = ALIGNED_ENTITIES_ANNEALER_CSV\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# create directories if they don't exist\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "KG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "EMBEDDINGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ENTITIES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WIKI_ENTITIES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ARXIV_ENTITIES_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc7687",
   "metadata": {},
   "source": [
    "## Section 2: Data Preparation\n",
    "- Fetch the Wikipedia and arXiv raw data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_titles = []\n",
    "arxiv_ids = []\n",
    "\n",
    "\n",
    "print(\"Fetching source corpora...\")\n",
    "wiki_summaries, wiki_titles = fetch_wiki_data()\n",
    "arxiv_abstracts, arxiv_ids = fetch_arxiv_data()\n",
    "print(f\"Wikipedia titles: {wiki_titles}\")\n",
    "print(f\"arXiv IDs: {arxiv_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df661f0",
   "metadata": {},
   "source": [
    "# Section 3: Build the KGs.\n",
    "\n",
    "- Run the NLP pipeline to perform Named Entity Recognition (NER) and Relationship Extraction (RE) on the raw data.\n",
    "\n",
    "- Use the entities and the relations between them to build two large unpruned graphs.\n",
    "\n",
    "- Take the unpruned graphs and reduce them to just a couple entities. In practice, those would be tha \"ambiguous\" entities whose alignment confidence score is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a69849",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBuilding and pruning knowledge graphs...\")\n",
    "build_unpruned_kgs(\n",
    "    wiki_data=wiki_summaries, \n",
    "    arxiv_data=arxiv_abstracts\n",
    ")\n",
    "prune_kgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886dae0",
   "metadata": {},
   "source": [
    "## Section 4: Generate Embeddings\n",
    "Generate the following embeddings:\n",
    "- Entity embeddings (using a GAE that fine-tunes the SciBERT embeddings)\n",
    "- Relation embeddings (using the SciBERT embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50efc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_EMBEDDINGS = True\n",
    "\n",
    "if RUN_EMBEDDINGS:\n",
    "    print(\"Generating relation embeddings...\")\n",
    "    generate_relation_embeddings()\n",
    "    print(\"\\nGenerating entity embeddings...\")\n",
    "    generate_entity_embeddings()\n",
    "else:\n",
    "    print(\"Skipping embedding generation; using cached tensors.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61f0a8",
   "metadata": {},
   "source": [
    "## Section 5: Formulate the problem as a QUBO and solve it\n",
    "Perform the QUBO formulation:\n",
    "$$\n",
    "H_{total} = \\underbrace{\\sum_{i,a}{-S(i, a) \\cdot x_{i,a}}}_{H_{\\text{node}}} + \\underbrace{\\sum_{i,j,a,b}{-w_{ij,ab} \\cdot x_{i,a} \\cdot x_{j,b}}}_{H_{\\text{structure}}} + \\underbrace{\\sum_{i} P_{1} \\sum_{a=1}^M \\sum_{b=a+1}^M x_{i,a} x_{i,b}}_{\\text{Constraint}\\ 1} + \\underbrace{\\sum_{a} P_{2} \\sum_{i=1}^N \\sum_{j=i+1}^N x_{i,a} x_{j,a}}_{\\text{Constraint}\\ 2}\n",
    "$$\n",
    "\n",
    "- Where:\n",
    "  - $x_{i,a}$: A binary variable (1 or 0) that is 1 if we align entity $i$ from KG1 with entity $a$ from KG2.\n",
    "  - $S(i,a)$: The similarity score between entity $i$ and $a$, derived from the GAE embeddings.\n",
    "  - $w_{ij,ab}$: The structural similarity weight, derived from the SciBERT relation embeddings.\n",
    "  - $P_1, P_2$: Large positive penalty constants to enforce the constraints.\n",
    "  - Constraint 1: Enforces that each entity $i$ in KG1 maps to at most one entity in KG2. If $i$ matches zero entities, the penalty is 0. If it matches one, the penalty is 0. If it matches two or more, the penalty is high.\n",
    "  - Constraint 2: Enforces that each entity $a$ in KG2 is mapped to by at most one entity from KG1. This allows entities to remain unaligned, making the formulation more robust to realistic KGs that do not have perfect 1-to-1 overlap.\n",
    "\n",
    "And solve it using quantum annealing (more details in the README.md file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOLVE_QUBO = True\n",
    "\n",
    "result = None\n",
    "if SOLVE_QUBO:\n",
    "    print(\"\\nSolving the alignment QUBO...\")\n",
    "    result = solve_alignment_with_annealer(\n",
    "        similarity_threshold=0.0,\n",
    "        max_structural_pairs=2000,\n",
    "        visualize=True\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping QUBO solve; falling back to existing artefacts.\")\n",
    "\n",
    "if result is None:\n",
    "    result = SimpleNamespace(\n",
    "        alignments=[],\n",
    "        energy=float(\"nan\"),\n",
    "        sampleset=None,\n",
    "        aligned_graph_path=KG_ALIGNED_PATH,\n",
    "        aligned_graph_html=(KG_DIR / \"kg_aligned.html\"),\n",
    "        alignment_report_path=ALIGNED_ENTITIES_ANNEALER_CSV,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67e3d33",
   "metadata": {},
   "source": [
    "## Section 6: Display HTML Visualizations\n",
    "Render the pruned graphs, aligned knowledge graph, and alignment report directly within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7824dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming KG_DIR, result, and ALIGNED_ENTITIES_ANNEALER_CSV are defined\n",
    "\n",
    "\n",
    "def _open_in_browser(path, title):\n",
    "    \"\"\"Open a local HTML file in the default browser.\"\"\"\n",
    "    path = Path(path)\n",
    "    webbrowser.open(f\"file://{path.resolve()}\")\n",
    "    display(HTML(f\"<p><i>Opening '{title}' in the browser...</i></p>\"))\n",
    "\n",
    "\n",
    "wiki_html = KG_DIR / \"pruned_wiki_kg.html\"\n",
    "arxiv_html = KG_DIR / \"pruned_arxiv_kg.html\"\n",
    "aligned_html = KG_DIR / \"kg_aligned.html\"\n",
    "# create the visualizations\n",
    "visualize_ttl(KG_WIKI_FINAL_PATH, wiki_html)\n",
    "visualize_ttl(KG_ARXIV_FINAL_PATH, arxiv_html)\n",
    "visualize_ttl(KG_ALIGNED_PATH, aligned_html)\n",
    "visualize_ttl(KG_WIKI_UNPRUNED_PATH, KG_DIR / \"unpruned_wiki_kg.html\")\n",
    "visualize_ttl(KG_ARXIV_UNPRUNED_PATH, KG_DIR / \"unpruned_arxiv_kg.html\")\n",
    "\n",
    "\n",
    "# aligned_html = getattr(result, \"aligned_graph_html\", None)\n",
    "# if aligned_html is None:\n",
    "#     aligned_html = KG_DIR / \"aligned_kg.html\"\n",
    "\n",
    "# Open HTML files in browser\n",
    "_open_in_browser(wiki_html, \"Pruned Wiki Knowledge Graph\")\n",
    "_open_in_browser(arxiv_html, \"Pruned arXiv Knowledge Graph\")\n",
    "_open_in_browser(aligned_html, \"Aligned Knowledge Graph\")\n",
    "_open_in_browser(KG_DIR / \"unpruned_wiki_kg.html\", \"Unpruned Wiki Knowledge Graph\")\n",
    "_open_in_browser(KG_DIR / \"unpruned_arxiv_kg.html\", \"Unpruned arXiv Knowledge Graph\")\n",
    "\n",
    "# # Display only the DataFrame in the notebook\n",
    "#display(HTML(\"<h3>Annealer Aligned Entities Report</h3>\"))\n",
    "display(pd.read_csv(ALIGNED_ENTITIES_ANNEALER_CSV))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KGA (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
